BASE_TASK_CONFIG_PATH: configs/tasks/vln_r2r.yaml
TRAINER_NAME: dagger
RUN_NAME: debug
ENV_NAME: VLNRLEnv
SIMULATOR_GPU_ID: 0
TORCH_GPU_ID: 0
TENSORBOARD_DIR: tensorboard_dirs/debug
# using compressed meshes, 8 procs fit on a single 1080 Ti GPU.
NUM_PROCESSES: 8
CHECKPOINT_FOLDER: data/checkpoints/vln/debug
# if file, eval just that checkpoint.
EVAL_CKPT_PATH_DIR: data/checkpoints/vln/debug
# any num greater than episode count evals every episode
TEST_EPISODE_COUNT: 100000
VIDEO_OPTION: []  # [disk, tensorboard]
VIDEO_DIR: videos/debug
EVAL:
  USE_CKPT_CONFIG: False
  SPLIT: val_seen
TEST:
  TEST_ENV_NAME: VLNTestEnv
  USE_CKPT_CONFIG: False
  SPLIT: test
  CKPT_FILE: data/checkpoints/vln/ckpt.0.pth

DAGGER:
  LR: 2.5e-4
  # set to 1 for student forcing and teacher forcing
  ITERATIONS: 10
  EPOCHS: 4
  UPDATE_SIZE: 5000
  BATCH_SIZE: 5
  # Student forcing: set to 0.0
  # Teacher forcing: set to 1.0
  # DAgger: 0.0 < P < 1.0
  P: 0.75
  USE_IW: True
  # ~1.5TB (in bytes)
  LMDB_MAP_SIZE: 1.65e+12
  TF_PRELOAD_FEATURES: False

VLN:
  inflection_weight_coef: 3.2
  INSTRUCTION_ENCODER:
    vocab_size: 2504
    max_length: 200
    use_pretrained_embeddings: True
    embedding_file: ./data/datasets/vln/mp3d/r2r/v1/preprocessed/embeddings.json
    dataset_vocab: ./data/datasets/vln/mp3d/r2r/v1/preprocessed/train/train.json.gz
    fine_tune_embeddings: False
    embedding_size: 50
    hidden_size: 128
    rnn_type: LSTM
  DEPTH_ENCODER:
    # SimpleDepthCNN or VlnResnetDepthEncoder
    cnn_type: VlnResnetDepthEncoder
    output_size: 128
    backbone: resnet50
    ddppo_checkpoint: data/dd-ppo-weights/gibson-2plus-resnet50.pth
  VISUAL_ENCODER:
    cnn_type: TorchVisionResNet50
    output_size: 256
  STATE_ENCODER:
    hidden_size: 512
    # Currently only works with GRU
    rnn_type: GRU

  BASELINE:
    use_prev_action: False
    ablate_instruction: False
    ablate_rgb: False
    ablate_depth: False

  RCM:
    # Set to True to use the RCM model
    use: False
    # Use the state encoding model in RCM
    # If false, will just concat inputs and run an RNN over them
    rcm_state_encoder: False

  PROGRESS_MONITOR:
    # Set to True to use a progress monitor
    use: False
    # Progress monitor loss multiplier
    alpha: 1.0
